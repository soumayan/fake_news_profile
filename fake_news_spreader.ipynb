{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pd.read_csv(\"/kaggle/input/merge-twitter/truth_spanish.txt\",header=None,names=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['new_label']=out.label.apply(lambda x:x[-1:])\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['profile_id']=out.label.apply(lambda x:x[:-4])\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['new_label'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "def parse_XML(df_cols):\n",
    "    #path = '/kaggle/input/merge-twitter/'\n",
    "    path = '/kaggle/input/twiter-profile-spanish/'\n",
    "    rows = []\n",
    "    ids = []\n",
    "    new = []\n",
    "    for filename in os.listdir(path):\n",
    "        if not filename.endswith('.xml'): continue\n",
    "        xml_file = os.path.join(path, filename)\n",
    "        xtree = et.parse(xml_file)\n",
    "        xroot = xtree.getroot() \n",
    "        xchild=xroot.getchildren()\n",
    "        for node in xchild:\n",
    "            res = []\n",
    "            qs=(node.findall(\"document\"))\n",
    "            for q in qs:\n",
    "                res.append(q.text)\n",
    "            rows.append({i: res[i] for i, _ in enumerate(df_cols)})   \n",
    "            for index, row in out.iterrows():\n",
    "                if(row['profile_id']==filename[:-4]):\n",
    "                    new.append({\"profile_id\":row['profile_id'],\"truth_val\":row['new_label']})\n",
    "                    out_df2=pd.DataFrame(new)\n",
    "                \n",
    "            ids.append({id:filename[:-4]})\n",
    "            out_df = pd.DataFrame(rows)\n",
    "        out_df['id']=ids\n",
    "    return out_df,out_df2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,df2=parse_XML([\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\n",
    "\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\",\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',13000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat([df,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process_data(documents,max_len=200):\n",
    "    for data in documents:\n",
    "        review = re.sub('[^a-zA-Z]', ' ', data)\n",
    "        url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        review = url.sub(r'',review)\n",
    "        html=re.compile(r'<.*?>')\n",
    "        review = html.sub(r'',review)\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'',review)\n",
    "        text = text[:max_len-2]\n",
    "\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for col in result:\n",
    "    if col == 'id'or col=='profile_id' or col=='truth_val':\n",
    "        continue\n",
    "    for i, row_value in result[col].iteritems():\n",
    "        result[col][i] = pre_process_data(row_value)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3'\n",
    "embed = hub.KerasLayer(module_url, name='USE_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result=np.zeros((300,103,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in result:\n",
    "    if col == 'id'or col=='profile_id' or col=='truth_val':\n",
    "        continue\n",
    "    for i, row_value in result[col].iteritems():\n",
    "        result[col][i] = embed([row_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result=new_result[:,0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_new=result.loc[:,'truth_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_new=np.asarray(output_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new=result.iloc[:,0:100]#iloc takes integer for column slicing ,loc takes index of columns for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new=np.asarray(result_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,300):\n",
    "    for j in range(0,100):\n",
    "        for k in range(512):\n",
    "            new_result[i,j,k]=result_new[i][j][0][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new=result_new.reshape(300,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import LSTM,Bidirectional,TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Input(shape=(100, 1),dtype=object))\n",
    "model.add(LSTM(128,return_sequences=True,input_shape=(100,512),dropout=0.3,recurrent_dropout=0.2))\n",
    "#model.add(TimeDistributed(Dense(128,activation='relu')))\n",
    "#model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "model.add(attention())\n",
    "model.add(Dense(1,activation='sigmoid',trainable=True))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(new_result, output_new, epochs=80,validation_split=0.1,batch_size=16,shuffle=True,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"/kaggle/working/model_spanish.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
